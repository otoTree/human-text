# DSL Compiler Environment Configuration

# =============================================================================
# Output Configuration
# =============================================================================

# Output format: yaml, json, proto
DSL_OUTPUT_FORMAT=yaml

# Compact mode - only output required fields
DSL_COMPACT_MODE=false

# Strict mode - return errors on parse failures
DSL_STRICT_MODE=true

# =============================================================================
# LLM Configuration
# =============================================================================

# Enable LLM-assisted parsing
DSL_LLM_ENABLED=true

# LLM provider: dashscope, openai, context_service
DSL_LLM_PROVIDER=dashscope

# LLM model name
DSL_LLM_MODEL=qwen-turbo

# API key for LLM service
DSL_LLM_API_KEY=your_api_key_here

# Custom API base URL (optional)
DSL_LLM_API_BASE=

# Request timeout in seconds
DSL_LLM_TIMEOUT=30

# Maximum retry attempts
DSL_LLM_MAX_RETRIES=3

# Save intermediate DSL code generated by LLM
DSL_LLM_SAVE_INTERMEDIATE=false

# Directory to save intermediate DSL files (optional, defaults to source_dir/llm_intermediate)
DSL_LLM_INTERMEDIATE_DIR=

# =============================================================================
# Performance Configuration
# =============================================================================

# Maximum file size in bytes (default: 10MB)
DSL_MAX_FILE_SIZE=10485760

# Maximum token count
DSL_MAX_TOKENS=100000

# Parse timeout in seconds
DSL_PARSE_TIMEOUT=60

# =============================================================================
# Debug Configuration
# =============================================================================

# Enable debug mode
DSL_DEBUG=false

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
DSL_LOG_LEVEL=INFO

# =============================================================================
# Context Service Configuration
# =============================================================================

# Context service URL (for internal LLM provider)
DSL_CONTEXT_SERVICE_URL=http://localhost:8001

# Context service timeout in seconds
DSL_CONTEXT_SERVICE_TIMEOUT=30

# =============================================================================
# Provider-Specific Configuration
# =============================================================================

# DashScope (Alibaba Cloud) API Key
DASHSCOPE_API_KEY=your_dashscope_key_here

# OpenAI API Key
OPENAI_API_KEY=your_openai_key_here

# OpenAI API Base URL (for custom endpoints)
OPENAI_API_BASE=https://api.openai.com/v1 